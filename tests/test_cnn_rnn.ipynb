{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/litvan007/NN_commands_recognition/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchtext\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from audio_augmentations import *\n",
    "\n",
    "import os, re, random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "import IPython.display as ipd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.cnn import ResidualCNN\n",
    "from models.encoder import Encoder\n",
    "from models.attention import Attention\n",
    "from models.model import Speech_recognition_model\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123456)\n",
    "np.random.seed(123456)\n",
    "torch.manual_seed(123456)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1, _ = torchaudio.load('../data/user_353665394/Сменить_3_1.wav')\n",
    "data_2, _ = torchaudio.load('../data/user_192546140/Вверх_6_3_new_1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/litvan007/NN_commands_recognition/.venv/lib/python3.11/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (241) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 30мс 10мс шаг\n",
    "n_fft = 480\n",
    "win_length = None\n",
    "hop_length = 160\n",
    "n_mels = 256\n",
    "n_mfcc = 256\n",
    "mfcc_transform = T.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=n_mfcc,\n",
    "    melkwargs={\n",
    "        \"n_fft\": n_fft,\n",
    "        \"n_mels\": n_mels,\n",
    "        \"hop_length\": hop_length,\n",
    "        \"mel_scale\": \"htk\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# mfcc_transform = torchaudio.transforms.MFCC(sample_rate=16000)\n",
    "# temp = mfcc_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 316])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_transform(data_1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([316, 256]), torch.Size([216, 256]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_X1 = mfcc_transform(data_1).transpose(1, 2).squeeze()\n",
    "pre_X2 = mfcc_transform(data_2).transpose(1, 2).squeeze()\n",
    "# input_lengths = [pre_X1.size(0), pre_X2.size(0)]\n",
    "pre_X1.shape, pre_X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 316, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.nn.utils.rnn.pad_sequence([pre_X1, pre_X2], batch_first=True, padding_value=0)\n",
    "X = X.unsqueeze(1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dim = 512\n",
    "n_rnn_layers = 5\n",
    "n_cnn_layers = 3\n",
    "n_class = 18\n",
    "stride = 2\n",
    "n_feats = 128\n",
    "dropout = 0.1\n",
    "bidirectional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)\n",
    "rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(3)\n",
    "        ])\n",
    "fully_connected = nn.Linear(n_feats*32, rnn_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 158, 128])\n",
      "torch.Size([2, 32, 128, 158])\n",
      "torch.Size([2, 4096, 158])\n",
      "torch.Size([2, 158, 4096])\n",
      "torch.Size([2, 158, 512])\n"
     ]
    }
   ],
   "source": [
    "X1 = cnn(X)\n",
    "print(X1.shape)\n",
    "X1 = X1.transpose(2, 3)\n",
    "X2 = rescnn_layers(X1)\n",
    "print(X2.shape)\n",
    "sizes = X2.size()\n",
    "X2 = X2.view(sizes[0], sizes[1] * sizes[2], sizes[3])\n",
    "print(X2.shape)\n",
    "X2 = X2.transpose(1, 2)\n",
    "print(X2.shape)\n",
    "X3 = fully_connected(X2)\n",
    "print(X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(rnn_dim, rnn_dim, n_rnn_layers,\n",
    "                      dropout=dropout, bidirectional=bidirectional,\n",
    "                      rnn_type='lstm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 158, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 158, 1024]), torch.Size([10, 2, 512]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, hidden = encoder(X3)\n",
    "temp = hidden[-1]\n",
    "output.shape, hidden[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp.transpose(0, 1)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Attention(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_output = attention(temp)\n",
    "attr_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim, rnn_dim//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim//2, n_class)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1196, -0.1270,  0.3311,  0.1149,  0.4776, -0.0073,  0.1990, -0.2371,\n",
       "         -0.0645, -0.1262,  0.1579, -0.0948, -0.6510,  0.3478,  0.0592, -0.0258,\n",
       "          0.5294,  0.5974],\n",
       "        [ 0.1298, -0.1323, -0.2997, -0.0238, -0.1419, -0.2612,  0.1929,  0.0642,\n",
       "         -0.2821, -0.3324, -0.1738, -0.3343, -0.0517,  0.5660, -0.0455, -0.2841,\n",
       "         -0.1107, -0.0975]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = classifier(attr_output)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([9, 11], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1547, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(logits, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5fb8b2ac1159a8f54b57f028b1e7265b953cba3f174d2e42f0525a72ffdb534"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
